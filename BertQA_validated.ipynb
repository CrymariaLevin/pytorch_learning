{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可执行的，完整的自定义问答模型（法律案件专精训练）\n",
    "### 1）将司法阅读理解CJRC数据集转换成transformers的Dataloader能识别的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.30.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(torch.__version__)\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 83554.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 124823.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 167117.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 函数转换CJRC数据为SQaAD格式\n",
    "# 详细数据结构参见其他文件\n",
    "\n",
    "import json\n",
    "import codecs\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# from transformers.data.datasets import QAExample\n",
    "\n",
    "def convert_file(input_file, output_file):\n",
    "    with codecs.open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        input_data = json.load(f)\n",
    "    output_data = []\n",
    "    for article in tqdm(input_data[\"data\"]):\n",
    "        single_data = {}\n",
    "        title = article[\"domain\"] + '-' + article[\"caseid\"].replace(\".txt\",\"\")\n",
    "        single_data['title'] = title\n",
    "        single_data['paragraphs'] = []\n",
    "        for paragraph in article[\"paragraphs\"]:        \n",
    "            context = paragraph[\"context\"]\n",
    "            qas_list = []\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                id = qa[\"id\"]\n",
    "                is_impossible = qa['is_impossible']\n",
    "                answers = qa[\"answers\"]\n",
    "    #             start_position = qa[\"answers\"][0][\"answer_start\"] if qa[\"answers\"] else -1\n",
    "                qas_list.append(dict(\n",
    "                    id=id,\n",
    "                    question=question,\n",
    "                    answers=answers,\n",
    "                    is_impossible=is_impossible\n",
    "                ))\n",
    "            single_data['paragraphs'].append({\"context\":context,\"qas\":qas_list})\n",
    "        output_data.append(single_data)\n",
    "        \n",
    "    output_json = {'version': '1.0'}\n",
    "    with codecs.open(output_file, \"w\", encoding=\"utf-8\") as writer:\n",
    "#         for example in output_data:\n",
    "#             writer.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "        output_json['data'] = output_data\n",
    "        writer.write(json.dumps(output_json, ensure_ascii=False))\n",
    "\n",
    "def convert_files(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for file_name in [\"big_train_data\", \"dev_ground_truth\", \"test_ground_truth\"]:\n",
    "        input_file = os.path.join(input_dir, f\"{file_name}.json\")\n",
    "        output_file = os.path.join(output_dir, f\"{file_name}.json\")\n",
    "        convert_file(input_file, output_file)\n",
    "    print(\"All Done\")\n",
    "        \n",
    "convert_files(\"./CJRC\",\"./CJRC/transfered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2）构建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertConfig\n",
    "from transformers.data.processors.squad import SquadV2Processor\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.data.data_collator import default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:14<00:00, 552.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 434.83it/s]\n"
     ]
    }
   ],
   "source": [
    "processor = SquadV2Processor()\n",
    "\n",
    "file_path = \"./CJRC/transfered\"\n",
    "train_file = \"big_train_data.json\"\n",
    "train_examples = processor.get_train_examples(data_dir=file_path, filename=train_file)\n",
    "\n",
    "dev_file = \"dev_ground_truth.json\"\n",
    "dev_examples = processor.get_dev_examples(data_dir=file_path, filename=dev_file)\n",
    "\n",
    "# test_file = \"test_ground_truth.json\"\n",
    "# test_examples = processor.get_test_examples(data_dir=file_path, filename=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# max_position_embeddings默认是512，因为我调整了traindata的max_seq_length=128，这里要改一下\n",
    "config = BertConfig.from_pretrained('chinese-bert-wwm')\n",
    "print(config.hidden_size)\n",
    "# config.max_position_embeddings = 128\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"chinese-bert-wwm\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squad_convert_examples_to_features是将SQuAD数据集转换成BERT模型可以处理的特征的函数。该函数主要包括以下参数：<br>\n",
    "\n",
    "examples: 输入的SQuAD数据集示例，包含问题、段落和答案。<br>\n",
    "tokenizer: BERT模型使用的分词器，用于将文本分割成标记（token）。<br>\n",
    "max_seq_length: 模型最大序列长度。如果超出此长度，则会被截断，否则将填充到相同长度。<br>\n",
    "doc_stride: 在转换示例时跨越文档的步幅。如果设置为0，则每个示例只涵盖一个段落，否则可能会跨越多个段落。<br>\n",
    "max_query_length: 最大问题长度。如果问题超出此长度，则会被截断。<br>\n",
    "is_training: 是否为训练模式。如果是，则输出包括每个示例的特征、真实标签、答案文本等，否则只输出特征。<br>\n",
    "\n",
    "通过调整这些参数，您可以改变模型的性能、内存使用量和训练时间。具体而言：<br>\n",
    "\n",
    "max_seq_length：增加此值会增加内存消耗，因为模型需要为每个特征构建输入张量。但是，如果此值太低，则会丢失重要的上下文信息，从而导致性能下降。<br>\n",
    "\n",
    "doc_stride：如果此值过大，则可能会出现潜在的信息丢失，导致性能下降。但是，如果此值过小，则会增加生成的特征数和内存消耗。因此，建议在实验中进行搜索以找到最佳值。<br>\n",
    "\n",
    "max_query_length：增加此值可能会增加训练时间和内存使用量，因为每个问题都需要用于生成特征。但是，此值应根据数据集中的典型查询长度进行选择，否则可能会丢失重要的信息。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|████████████████████████████████████████| 39333/39333 [07:30<00:00, 87.27it/s]\n",
      "add example index and unique id: 100%|███████████████████████████████████████| 39333/39333 [00:00<00:00, 743661.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86463"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.data.processors.squad import SquadV2Processor, squad_convert_examples_to_features\n",
    "from transformers.data.datasets.squad import SquadDataset\n",
    "\n",
    "# 训练集\n",
    "train_features = squad_convert_examples_to_features(train_examples, \n",
    "                                                       tokenizer, \n",
    "                                                       max_seq_length=512, \n",
    "                                                       doc_stride=128, \n",
    "                                                       max_query_length=64, \n",
    "                                                       is_training=True)\n",
    "\n",
    "# 调整最大长度以配合硬件水平，但会影响性能\n",
    "# train_features = squad_convert_examples_to_features(train_examples, \n",
    "#                                                        tokenizer, \n",
    "#                                                        max_seq_length=128, \n",
    "#                                                        doc_stride=32, \n",
    "#                                                        max_query_length=16, \n",
    "#                                                        is_training=True)\n",
    "\n",
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 硬件原因，先搞500个试试，确保模型能跑起来\n",
    "train_features = train_features[:700]\n",
    "\n",
    "# 将features中的每个样本的input_ids、attention_mask、token_type_ids、start_positions和end_positions提取出来，并组成一个TensorDataset\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_attention_masks = torch.tensor([f.attention_mask for f in train_features], dtype=torch.long)\n",
    "all_token_type_ids = torch.tensor([f.token_type_ids for f in train_features], dtype=torch.long)\n",
    "all_start_positions = torch.tensor([f.start_position for f in train_features], dtype=torch.long)\n",
    "all_end_positions = torch.tensor([f.end_position for f in train_features], dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(all_input_ids, all_attention_masks, all_token_type_ids, all_start_positions, all_end_positions)\n",
    "\n",
    "# 使用DataLoader将训练集加载到内存中\n",
    "batch_size = 32\n",
    "# batch_size = 16\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertModel\n",
    "from transformers import InputExample\n",
    "from transformers.data.processors.squad import SquadV2Processor, squad_convert_examples_to_features\n",
    "from transformers.data.datasets.squad import SquadDataset\n",
    "\n",
    "\n",
    "# 模型接受的输入应该是一个包含input_ids、attention_mask、token_type_ids、start_positions和end_positions参数的字典，\n",
    "# 其中input_ids、attention_mask和token_type_ids参数是标准的BERT输入，start_positions和end_positions参数是答案的开始和结束位置。\n",
    "\n",
    "# 如果提供了start_positions和end_positions参数，模型将返回损失；否则，将返回答案的logits。\n",
    "# 在训练时，使用BertTokenizer将原始文本转换为模型所需的输入格式，并优化模型的参数。\n",
    "\n",
    "class BertQA(nn.Module):\n",
    "    def __init__(self, pretrained_path):\n",
    "        super(BertQA, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_path, config=config)\n",
    "        self.dropout = torch.nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.qa_outputs = torch.nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
    "                start_positions=None, end_positions=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "\n",
    "\n",
    "        '''\n",
    "        sequence_output 是 BERT 模型最后一个 Transformer block 的每个 token 对应的隐藏状态，\n",
    "        它的张量形状为 [batch_size, sequence_length, hidden_size]。\n",
    "        pooled_output 是对最后一个 Transformer block 的所有 token 进行池化后得到的向量，\n",
    "        它的张量形状为 [batch_size, hidden_size]。\n",
    "        \n",
    "        在 QA 模型中，我们需要对输入的问题和文本段落进行建模，然后预测答案的起始位置和结束位置。\n",
    "        具体来说，我们可以将问题和文本段落同时输入 BERT 模型，\n",
    "        然后使用 BERT 输出的 sequence_output 来计算每个位置上的答案起始位置和结束位置的预测值（即 logits），最终得到最可能的答案区间。\n",
    "        \n",
    "        而 pooled_output 通常被用于额外的任务，如分类任务或序列标注任务等，例如可以使用 pooled_output 来预测其他相关问题的标签或实体的类别。\n",
    "        '''\n",
    "        sequence_output = outputs[0]  # (batch_size, sequence_length, hidden_size)\n",
    "        pooled_output = outputs[1]  # (batch_size, hidden_size)\n",
    "        print(\"sequence_output's shape:\",sequence_output.shape) # [16, 512, 768]\n",
    "        print(\"pooled_output's shape:\",pooled_output.shape) # [16, 768]\n",
    "\n",
    "        # Flatten the sequence tensor\n",
    "#         flattened_sequence_output = sequence_output.view(-1, self.bert.config.hidden_size)\n",
    "\n",
    "#         pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        # [src_len, batch_size,2]\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        print(\"start_logits's shape:\",start_logits.shape) #[16,512,1]\n",
    "        print(\"end_logits's shape:\",end_logits.shape)\n",
    "        # [src_len, batch_size,1], [src_len, batch_size,1]\n",
    "        start_logits = start_logits.squeeze(-1).transpose(0,1)\n",
    "        end_logits = end_logits.squeeze(-1).transpose(0,1)\n",
    "        if start_positions is not None and end_positions is not None:          \n",
    "            \n",
    "#             ignored_index = start_logits.size(1) # 取输入序列的长度\n",
    "#             start_logits.clamp_(0,ignored_index)\n",
    "#             end_logits.clamp_(0,ignored_index)\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss(ignored_index=ignored_index)\n",
    "    \n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            print(\"start_positions's shape:\", start_positions.shape)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "            return total_loss, start_logits, end_logits\n",
    "        else:\n",
    "            return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at chinese-bert-wwm were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertQA(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化模型和参数\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "model = BertQA('chinese-bert-wwm')\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "# 这里是设置不应该添加正则化项的参数，一般是BN层的可训练参数及卷积层和全连接层的 bias\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_parameters, lr=3e-5)\n",
    "\n",
    "# 将模型转移到GPU（如果可用）\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 101, 1155,  815,  ...,    0,    0,    0],\n",
      "        [ 101, 1155,  815,  ..., 4500, 3326,  102],\n",
      "        [ 101, 4506, 3378,  ...,  865, 2157,  102],\n",
      "        ...,\n",
      "        [ 101, 1403, 1333,  ..., 4135, 2154,  102],\n",
      "        [ 101, 1352, 3175,  ..., 5385, 1104,  102],\n",
      "        [ 101, 3289,  166,  ..., 1357, 4638,  102]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = next(iter(train_dataloader))\n",
    "print(d)\n",
    "# 使用index标记各个参数，顺序如下\n",
    "# input_ids, attention_masks, token_type_ids, start_positions, end_positions\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果显存不够用，可以尝试以下方法对训练参数进行调整：<br>\n",
    "\n",
    "减小批次大小 (batch_size)：默认情况下，每个批次训练数据集中有16个样本。您可以将此值减小为8、4或更小以减少内存使用量。但是，批次大小太小可能会导致梯度稳定性下降，并增加训练时间。<br>\n",
    "\n",
    "减少序列长度 (max_seq_length)：默认情况下，BERT模型可以处理长度为512的序列。您可以将此值减小为256、128或更小以减少内存使用量。但是，序列长度太短可能会丢失重要的上下文信息，导致性能下降。<br>\n",
    "\n",
    "减少训练步数 (num_train_steps)：默认情况下，训练步数为1000。您可以将此值减小为500、200或更小以减少内存使用量。但是，训练步数太少可能会导致模型欠拟合，并且在执行推理时，模型无法很好地泛化。<br>\n",
    "\n",
    "减少并行数：如果您使用多个GPU并行训练模型，则可以尝试减少GPU数量以减少内存使用量。<br>\n",
    "\n",
    "当您对训练参数进行调整时，请注意，在执行过程中，一些训练设置可能会导致模型的性能下降。因此，您应该评估模型的测试/验证数据集上的性能，以确保所做的更改不会对性能产生负面影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output's shape: torch.Size([32, 512, 768])\n",
      "pooled_output's shape: torch.Size([32, 768])\n",
      "start_logits's shape: torch.Size([32, 512, 1])\n",
      "end_logits's shape: torch.Size([32, 512, 1])\n",
      "start_positions's shape: torch.Size([32])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (512) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m end_positions \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 21\u001b[0m loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mstart_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mend_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[64], line 73\u001b[0m, in \u001b[0;36mBertQA.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, start_positions, end_positions)\u001b[0m\n\u001b[0;32m     71\u001b[0m loss_fct \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_positions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, start_positions\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 73\u001b[0m start_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m end_loss \u001b[38;5;241m=\u001b[39m loss_fct(end_logits, end_positions)\n\u001b[0;32m     75\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m (start_loss \u001b[38;5;241m+\u001b[39m end_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (512) to match target batch_size (32)."
     ]
    }
   ],
   "source": [
    "# 训练批次\n",
    "num_epochs = 3\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    # 开始一个epoch的训练过程\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, batch_data in enumerate(train_dataloader):\n",
    "#         input_ids = batch_data['input_ids'].to(device)\n",
    "#         attention_mask = batch_data['attention_mask'].to(device)\n",
    "#         start_positions = batch_data['start_positions'].to(device)\n",
    "#         end_positions = batch_data['end_positions'].to(device)\n",
    "        input_ids = batch_data[0].to(device)\n",
    "        attention_mask = batch_data[1].to(device)\n",
    "        token_type_ids = batch_data[2].to(device) \n",
    "        start_positions = batch_data[3].to(device)\n",
    "        end_positions = batch_data[4].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, _, _ = model(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask,\n",
    "                           token_type_ids = token_type_ids,\n",
    "                           start_positions=start_positions,\n",
    "                           end_positions=end_positions)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 每隔10个batch打印一次训练结果\n",
    "        if batch_idx % 10 == 9:\n",
    "            avg_loss = running_loss / 10\n",
    "            print(f'Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_dataloader)}, Avg. Loss: {avg_loss:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "# 保存训练好的模型\n",
    "torch.save({'state_dict': model.state_dict()}, 'self_QA/bert_model/cjrc_model_dict.pth.bar')\n",
    "# tokenizer.save_pretrained('self_QA/bert_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
