{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "wine_path = \"../data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",\n",
    "                         skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 12])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意此时只进行回归，但是这个数据实际上是分类\n",
    "\n",
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4898, 11]) torch.Size([4898])\n"
     ]
    }
   ],
   "source": [
    "# 先划分label\n",
    "data = wineq[:,:-1]\n",
    "labels = wineq[:,-1]\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6.],\n",
       "         [6.],\n",
       "         [6.],\n",
       "         ...,\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [6.]]),\n",
       " torch.Size([4898, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = labels.unsqueeze(-1)\n",
    "target,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3919]), torch.Size([979]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "\n",
    "n_samples = data.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices.shape, val_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
      "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01]) torch.Size([11])\n",
      "std: tensor([8.4387e-01, 1.0079e-01, 1.2102e-01, 5.0721e+00, 2.1848e-02, 1.7007e+01,\n",
      "        4.2498e+01, 2.9909e-03, 1.5100e-01, 1.1413e-01, 1.2306e+00]) torch.Size([11])\n",
      "\n",
      "\n",
      "after normalization:\n",
      "\n",
      "tensor([-1.8147e-07,  2.1612e-07,  6.4643e-08,  4.1278e-08,  4.9456e-08,\n",
      "        -8.7229e-08,  2.0250e-08, -5.4518e-08,  8.3471e-07,  4.3498e-07,\n",
      "         4.9456e-08])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000])\n",
      "torch.Size([3919, 11])\n"
     ]
    }
   ],
   "source": [
    "data_norm = data\n",
    "\n",
    "# print(torch.mean(data_norm,dim=0))\n",
    "# print(data_norm[:,0].mean())\n",
    "\n",
    "mean_data = torch.mean(data_norm, dim=0)\n",
    "std_data = torch.std(data_norm, dim=0)\n",
    "\n",
    "print('mean:',mean_data, mean_data.shape)\n",
    "print('std:',std_data,std_data.shape)\n",
    "\n",
    "data_norm = (data_norm - mean_data)/std_data\n",
    "\n",
    "print('\\n')\n",
    "print('after normalization:\\n')\n",
    "print(torch.mean(data_norm,dim=0))\n",
    "# print(data_norm[:,0].mean(),data_norm[:,1].mean())\n",
    "print(torch.std(data_norm,dim=0))\n",
    "\n",
    "train_data = data_norm[train_indices]\n",
    "print(train_data.shape)\n",
    "train_label = target[train_indices]\n",
    "\n",
    "val_data = data_norm[val_indices]\n",
    "val_label = target[val_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[ 0, -1],\n",
      "        [ 2,  1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., -1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "print(a)\n",
    "b = torch.tensor([1,3])\n",
    "s = torch.tensor([2,1])\n",
    "print(a-b)\n",
    "(a-b)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=11, out_features=16, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "neuron_count = 16\n",
    "input_shape = train_data.shape[1]\n",
    "\n",
    "seq_model = nn.Sequential(\n",
    "            nn.Linear(input_shape, neuron_count), # <1>\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(neuron_count, 1)) # <2>\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "# nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opimizer\n",
    "# SGD\n",
    "optimizer = optim.Adam(seq_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, data_train, label_train,\n",
    "                  data_test, label_test):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_predict = model(data_train) # <1>\n",
    "        loss_train = loss_fn(train_predict, label_train)\n",
    "\n",
    "        test_predict = model(data_test) # <1>\n",
    "        loss_val = loss_fn(test_predict, label_test)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.4742, Validation loss 0.5239\n",
      "Epoch 1000, Training loss 0.4688, Validation loss 0.5234\n",
      "Epoch 2000, Training loss 0.4627, Validation loss 0.5260\n",
      "Epoch 3000, Training loss 0.4577, Validation loss 0.5251\n",
      "Epoch 4000, Training loss 0.4516, Validation loss 0.5221\n",
      "Epoch 5000, Training loss 0.4458, Validation loss 0.5264\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    data_train = train_data,\n",
    "    label_train = train_label, \n",
    "    data_test = val_data,\n",
    "    label_test = val_label)\n",
    "    \n",
    "# print('output', seq_model(val_data)) # 预测值\n",
    "# print('answer', val_label) # 实际值\n",
    "# print('hidden', seq_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
